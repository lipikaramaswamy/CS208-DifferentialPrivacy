{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW4a\n",
    "\n",
    "\n",
    "#### CS208\n",
    "#### Lipika Ramaswamy\n",
    "\n",
    "https://github.com/lipikaramaswamy/cs208_lr/tree/master/homework/HW4a\n",
    "\n",
    "Collaborators: Bhaven Patel, Karina Huang and Anthony Rentsch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup\n",
    "# rm(list=ls())\n",
    "library(ggplot2)\n",
    "library(repr)\n",
    "\n",
    "rm(list=ls())\t\t# Remove any objects in memory\n",
    "set.seed(123)\n",
    "\n",
    "# Random draw from Laplace distribution\n",
    "#\n",
    "# mu numeric, center of the distribution\n",
    "# b numeric, spread\n",
    "# size integer, number of draws\n",
    "# \n",
    "# return Random draws from Laplace distribution\n",
    "# example:\n",
    "# \n",
    "# rlap(size=1000)\n",
    "\n",
    "rlap = function(mu=0, b=1, size=1) {\n",
    "    p <- runif(size) - 0.5\n",
    "    draws <- mu - b * sgn(p) * log(1 - 2 * abs(p))\n",
    "    return(draws)\n",
    "}\n",
    "\n",
    "# Sign function\n",
    "# \n",
    "# Function to determine what the sign of the passed values should be.\n",
    "#\n",
    "# x numeric, value or vector or values\n",
    "# return The sign of passed values\n",
    "# example:\n",
    "#\n",
    "# sgn(rnorm(10))\n",
    "\n",
    "sgn <- function(x) {\n",
    "    return(ifelse(x < 0, -1, 1))\n",
    "}\n",
    "\n",
    "## Bound/Censor/Clip a variable to a range\n",
    "clip <- function(x, lower, upper){\n",
    "\tx.clipped <- x\n",
    "\tx.clipped[x.clipped<lower] <- lower\n",
    "\tx.clipped[x.clipped>upper] <- upper\n",
    "\treturn(x.clipped)\t\n",
    "}\n",
    "\n",
    "## Differentially private mean release\n",
    "meanRelease <- function(x, lower, upper, epsilon){\n",
    "\tn <- length(x)\n",
    "\n",
    "\tsensitivity <- (upper - lower)/n\n",
    "\tscale <- sensitivity / epsilon\n",
    "\n",
    "\tx.clipped <- clip(x, lower, upper)\n",
    "\tsensitiveValue <- mean(x.clipped)\n",
    "\tDPrelease <- sensitiveValue + rlap(mu=0, b=scale, size=1)\n",
    "\n",
    "\treturn(list(release=DPrelease, true=sensitiveValue))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Learning Conjunctions in the SQ Model\n",
    "\n",
    "We are given a data set $D = ((x_1, y_1), \\ldots (x_n, y_n))$ where $x_i \\in \\{0,1\\}^d$ anf $y_i \\in \\{0,1\\}$. We want a (local or centralized) differentially private algorithm $M(D)$ that outputs a subset $\\hat{S} \\subseteq \\{ 1, \\ldots, d\\}$ of the variables such that conjunction of the $x$-variables in $\\hat{S}$ predicts the variable $y$ well. \n",
    "\n",
    "Specifically, following Valiant's probably approximately correct (PAC) model, we will measure utility as follows. Suppose that $D$ consists of $n$ iid draws from an unknown distribution $\\mathcal{P}$ on $\\{0,1\\}^d \\times \\{0,1\\}$. Furthermore, suppose that there is an (unknown) set $S \\subseteq \\{ 1, \\ldots, d\\}$ such that\n",
    "\n",
    "$$\\underset{(x,y)\\sim \\mathcal{P}}{Pr} \\big[ y = \\underset{j\\in S}{\\bigwedge} x [ j ] \\big] = 1.$$\n",
    "\n",
    "That is, $y$ can be perfectly predicted by some conjunction. (Note that here and below, the notation (x,y) refers to a single labelled example drawn from $\\mathcal{P}$, not a dataset of $n$ such values. We will use $D=((x_1, y_1), \\ldots, (x_n, y_n))$ for the dataset). \n",
    "\n",
    "Then the goal of $M$ is to output $\\hat{S}$ that minimizes the expected classification error:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"q1.png\" alt=\"Drawing\" style=\"width: 700px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(a) Describe and implement centralized and local DP versions of the above SQ algorithm, dividing the privacy budget equally among each of the $d$ estimates $\\hat{p}_j$. Keep the threshold $t$ as a free parameter that you can choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Centralized DP version of SQ algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The centralized DP version of the algorithm will involve the following: \n",
    "- Use the dataset D to obtain a true value for $p_j$ where $j=1,\\ldots,d$.\n",
    "    - Since $p_j = \\underset{(x,y)\\sim \\mathcal{P}}{Pr} [x[j] = 0 \\wedge y = 1]$, taking the ratio of the bit at the jth attribute and dividing it by the value of the outcome when it is 1 will always yield 0.\n",
    "    - Logical indexing can be used to determine the sum of rows where $x[j] = 0$ and $y = 1$, and dividing this sum by the total number of rows in the dataset yields the required $p_j$.\n",
    "- Add Laplace noise with scale $\\frac{1/n}{\\epsilon/d} = \\frac{d}{n\\epsilon}$ to each $p_j$ and yield $\\hat{p}_j$. \n",
    "    - The global sensitivity of the proportion of n rows where the conjunction of the jth bit is 0 and the outcome is 1, is 1/n.\n",
    "    - There will be d releases, one for each attribute, so we divide the epsilon equally.\n",
    "- Given a threshold $t$, output the set of attributes where the estimate, $\\hat{p}_j$, is less than the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local DP version of SQ algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "localRelease <- function(x, values=c(-1,1), epsilon){\n",
    "    draw <- runif(n=1, min=0, max=1)\n",
    "    cutoff <- 1/(1+exp(epsilon)) # probability that i want to flip the value, less than 1/2\n",
    "    if(draw<cutoff){\n",
    "        to.return <- values[!values%in%x]\n",
    "        return(to.return)\n",
    "    }\n",
    "    else{\n",
    "        return(x)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "correction <- function(release, epsilon){\n",
    "    inflation <- (exp(epsilon) + 1)/(exp(epsilon) - 1)\n",
    "    expectation <- mean(release * inflation)\n",
    "    return(expectation)\n",
    "}\n",
    "\n",
    "\n",
    "# works on data in the zero to one scale\n",
    "correction01 <- function(release, epsilon, sensitivity=1){\n",
    "    inflation <- (exp(epsilon/sensitivity) + 1)/(exp(epsilon/sensitivity) - 1)\n",
    "    release.trans <- (release-0.5)*2\n",
    "    expectation <- release.trans * inflation\n",
    "    expectation.trans <- expectation/2 + 0.5\n",
    "    return(expectation.trans)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpSQAlg <- function(mydata, \n",
    "                    epsilon, \n",
    "                    t, \n",
    "                    central = FALSE, \n",
    "                    local = FALSE){\n",
    "    \n",
    "    # get dimensions of data\n",
    "    nrows = dim(mydata)[1]\n",
    "    nattributes = dim(mydata)[2] - 1\n",
    "    \n",
    "    # make an empty matrix to store truth vals for probabilities\n",
    "    probs <- matrix(NA, nrow = nrows, ncol = nattributes)\n",
    "    \n",
    "    # rows with y = 0 will have p = 0\n",
    "    # look only at rows with y = 1 to get p\n",
    "    smaller.data <- mydata[mydata[,nattributes+1] == 1,]\n",
    "    \n",
    "    # make an empty matrix to store truth vals for probabilities\n",
    "    probs <- matrix(NA, nrow = dim(smaller.data)[1], ncol = nattributes)\n",
    "    \n",
    "    # get conjunction matrix\n",
    "    for(j in 1:nattributes){\n",
    "        probs[,j] <- smaller.data[,j]/smaller.data[,nattributes+1]\n",
    "        probs[,j] <- probs[,j] == 0\n",
    "        }\n",
    "\n",
    "    # get the mean of columns to get true vals\n",
    "    true.sums.vec <- colSums(probs)\n",
    "    true.p.vec <- true.sums.vec/nrows\n",
    "\n",
    "\n",
    "    ## implement centralized DP mechanism\n",
    "    if (central == TRUE){\n",
    "\n",
    "        # draw laplace noise\n",
    "        noise <- rlap(mu=0, b = nattributes/(nrows * epsilon), size=nattributes)\n",
    "\n",
    "        # add noise to means\n",
    "        noisy.p.vec <- true.p.vec + noise\n",
    "\n",
    "        # get set S hat, where noisy probabilities are below threshold\n",
    "        S.hat <- which(noisy.p.vec < t)\n",
    "        S.hat.colnames <- colnames(mydata)[S.hat]\n",
    "\n",
    "        return(list(indices = S.hat, colnames = S.hat.colnames))\n",
    "    }\n",
    "    \n",
    "    ## implement local DP mechanism\n",
    "    if(local == TRUE){\n",
    "        probs.local <- probs\n",
    "        probs.local[probs.local==0] <- -1\n",
    "        \n",
    "        for(row in 1:nrow(probs.local)){\n",
    "            for(col in 1:ncol(probs.local)){\n",
    "                probs.local[row, col] = localRelease(x=probs.local[row, col], values=c(-1,1), epsilon=epsilon)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        noisy.sums.vec <- colSums(probs.local)\n",
    "        noisy.p.vec <- true.sums.vec/nrows      \n",
    "        \n",
    "        DPmeans <- correction01(noisy.p.vec, epsilon=epsilon, sensitivity = 1)\n",
    "        cat(DPmeans)\n",
    "        \n",
    "        # get set S hat, where noisy probabilities are below threshold\n",
    "        S.hat <- which(DPmeans < t)\n",
    "        S.hat.colnames <- colnames(mydata)[S.hat]\n",
    "        \n",
    "        return(list(indices = S.hat, colnames = S.hat.colnames))\n",
    "        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "mydata <- read.csv('../../data/hw4testdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dpSQAlg(mydata, epsilon = 1, central = TRUE, t = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5819767 -0.5819767 -0.5819767 -0.4478765 -0.4510142 -0.449586 -0.4487854 -0.4482444 -0.4502785 -0.449889"
     ]
    }
   ],
   "source": [
    "res2 = dpSQAlg(mydata, epsilon = 1, local = TRUE, t = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
